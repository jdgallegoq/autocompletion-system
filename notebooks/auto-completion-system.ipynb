{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation: auto-completion system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.s3_class import S3Functions\n",
    "\n",
    "s3_funcs = S3Functions(bucket_name='jdgallegoq-text-gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x136e6edb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproduce same results\n",
    "SEED = 42\n",
    "# seed on torch\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64776"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "with s3_funcs.read_object('Dailog-dataset.dialogs_dataset') as f:\n",
    "    dialogs = pickle.load(f)\n",
    "len(dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Well that sounda good',\n",
       " 'That wont work then',\n",
       " ' That is fine',\n",
       " \"Yeah, she really likes sushi and we haven't had it in a while\",\n",
       " \"Wow, that's a lot\",\n",
       " 'When will they be finished with my car?',\n",
       " 'Ok, can you book that for me please, under Smith?',\n",
       " 'ok, and when will this be ready',\n",
       " 'How do the price for food range there?',\n",
       " \"I'll do a stadium seat, since the front rows are too close\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a sample of 10\n",
    "random.sample(dialogs, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning\n",
    "dialogs_clean = []\n",
    "\n",
    "for i in dialogs:\n",
    "    # remove everything except alphabets\n",
    "    i = re.sub(\"[^a-zA-Z' ]\", \"\", i)\n",
    "    # convert text to lowercase\n",
    "    i = i.lower()\n",
    "    # add cleaned text to the list\n",
    "    dialogs_clean.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ok perfect thanks',\n",
       " \"good evening can you check if there are any reservations available for tomorrow at eddie v's or jefferys\",\n",
       " 'sounds good just use my account information to get the tickets',\n",
       " 'okay that sounds good',\n",
       " 'what does it end up coming out to',\n",
       " 'just checked it i got it',\n",
       " 'also let the limo driver know the location change',\n",
       " 'find me the number for the fire pit on main street yamomma ga',\n",
       " 'thank you so much',\n",
       " 'how about a large that sounds good']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a sample of 10\n",
    "random.sample(dialogs_clean, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term frequency\n",
    "all_words = \" \".join(dialogs_clean).split()\n",
    "\n",
    "# create dictionary\n",
    "words_dict = {}\n",
    "for word in all_words:\n",
    "    if word in words_dict:\n",
    "        # increment count by 1\n",
    "        words_dict[word] = words_dict[word] + 1\n",
    "    else:\n",
    "        words_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uppermiddle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shoots</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>geesh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  count\n",
       "0  uppermiddle      1\n",
       "1       shoots      1\n",
       "2        geesh      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprare a dataset\n",
    "words_df = pd.DataFrame({\n",
    "    \"word\": list(words_dict.keys()),\n",
    "    \"count\": list(words_dict.values())\n",
    "})\n",
    "# sort\n",
    "words_df = words_df.sort_values(by='count')\n",
    "words_df.reset_index(inplace=True, drop=True)\n",
    "words_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11145</th>\n",
       "      <td>the</td>\n",
       "      <td>15406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11146</th>\n",
       "      <td>i</td>\n",
       "      <td>19654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  count\n",
       "11145  the  15406\n",
       "11146    i  19654"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11147"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocab size\n",
    "len(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rare words distribution in the vocabulary: 69.03\n",
      "Rare words coverage in the corpus: 2.27\n"
     ]
    }
   ],
   "source": [
    "# find and replace rare tokens\n",
    "# replace with UNKNOW TOKEN\n",
    "# define rarity threshold\n",
    "rare_thres = 4\n",
    "\n",
    "# get percentage of rare tokens\n",
    "rare_words_count = len(words_df[words_df['count']<rare_thres]['word'])\n",
    "total_word = len(words_df)\n",
    "rare_dist = rare_words_count / total_word\n",
    "\n",
    "rare_cover = words_df[words_df['count'] < rare_thres]['count'].sum()/words_df['count'].sum()\n",
    "\n",
    "print(f\"Rare words distribution in the vocabulary: {rare_dist*100:.2f}\")\n",
    "print(f\"Rare words coverage in the corpus: {rare_cover*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract rare words in a list\n",
    "rare_words = words_df[words_df['count'] < rare_thres]['word'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64776/64776 [00:10<00:00, 6369.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a pattern with regex\n",
    "pattern = \"\"\n",
    "for i in rare_words:\n",
    "    pattern += \" {} |\".format(i)\n",
    "\n",
    "# remove the last '|' from the pattern\n",
    "pattern = pattern[:-1]\n",
    "\n",
    "# empty list for clean text\n",
    "dialogs_clean_no_rare_words = []\n",
    "for d in tqdm(dialogs_clean):\n",
    "    text = re.sub(pattern, \" <unk> \", d)\n",
    "    dialogs_clean_no_rare_words.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['does it serve traditional chinese dessert',\n",
       " 'how much extra time to reach <unk> ',\n",
       " 'ok lets reserve a table for dinner at hakkasan',\n",
       " 'hello i need to get a car please',\n",
       " 'holiday inn <unk> parkconv <unk> convention center drive <unk> park il',\n",
       " 'bowling alley <unk> highway <unk> park il',\n",
       " 'what types of cars does uber have',\n",
       " \"what's the price difference\",\n",
       " 'ok get me the cheapest please',\n",
       " 'ok then get me the next level']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogs_clean_no_rare_words[520:530]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprare sequences\n",
    "# 1. define sequence lenght based on distribution of sentence lenghts\n",
    "def create_seq(text, seq_lenght=5):\n",
    "    sequence = []\n",
    "    if len(text.split())>seq_lenght:\n",
    "        for i in range(seq_lenght, len(text.split())):\n",
    "            seq = text.split()[i-seq_lenght: i+1]\n",
    "            sequence.append(\" \".join(seq))\n",
    "\n",
    "        return sequence\n",
    "\n",
    "    else:\n",
    "        return [text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = [create_seq(i) for i in dialogs_clean_no_rare_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"hi i'm looking to book a\",\n",
       "  \"i'm looking to book a table\",\n",
       "  'looking to book a table for',\n",
       "  'to book a table for korean',\n",
       "  'book a table for korean fod'],\n",
       " ['somewhere in southern nyc maybe the',\n",
       "  'in southern nyc maybe the east',\n",
       "  'southern nyc maybe the east village'],\n",
       " [\"we don't want to sit at\",\n",
       "  \"don't want to sit at the\",\n",
       "  'want to sit at the bar',\n",
       "  'to sit at the bar but',\n",
       "  'sit at the bar but anywhere',\n",
       "  'at the bar but anywhere else',\n",
       "  'the bar but anywhere else is',\n",
       "  'bar but anywhere else is fine'],\n",
       " ['what times are available'],\n",
       " [\"yikes we can't do those times\"],\n",
       " ['let me check'],\n",
       " [\"great let's book that\"],\n",
       " [\"no that's it just book\"],\n",
       " ['hi i would like to see',\n",
       "  'i would like to see if',\n",
       "  'would like to see if the',\n",
       "  'like to see if the movie',\n",
       "  'to see if the movie what',\n",
       "  'see if the movie what men',\n",
       "  'if the movie what men want',\n",
       "  'the movie what men want is',\n",
       "  'movie what men want is playing',\n",
       "  'what men want is playing here'],\n",
       " ['yes for me and a friend',\n",
       "  'for me and a friend so',\n",
       "  'me and a friend so two',\n",
       "  'and a friend so two tickets',\n",
       "  'a friend so two tickets please']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"hi i'm looking to book a\",\n",
       " \"i'm looking to book a table\",\n",
       " 'looking to book a table for',\n",
       " 'to book a table for korean',\n",
       " 'book a table for korean fod',\n",
       " 'somewhere in southern nyc maybe the',\n",
       " 'in southern nyc maybe the east',\n",
       " 'southern nyc maybe the east village',\n",
       " \"we don't want to sit at\",\n",
       " \"don't want to sit at the\",\n",
       " 'want to sit at the bar',\n",
       " 'to sit at the bar but',\n",
       " 'sit at the bar but anywhere',\n",
       " 'at the bar but anywhere else',\n",
       " 'the bar but anywhere else is']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge to a single list\n",
    "seqs = sum(seqs, [])\n",
    "seqs[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205346"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count sequences\n",
    "len(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"hi i'm looking to book\", \"i'm looking to book a\")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create input and target sequences (x and y)\n",
    "x = []\n",
    "y = []\n",
    "for s in seqs:\n",
    "    x.append(\" \".join(s.split()[:-1]))\n",
    "    y.append(\" \".join(s.split()[1:]))\n",
    "\n",
    "x[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3574, 'veg')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create token-integer mappings\n",
    "# text-gen works like generation integers\n",
    "# that need to be converted into tokens by mapping\n",
    "# the vocabulary\n",
    "\n",
    "int2token = {}\n",
    "count = 1\n",
    "\n",
    "for w in set(\" \".join(dialogs_clean_no_rare_words).split()):\n",
    "    int2token[count] = w\n",
    "    count += 1\n",
    "\n",
    "# token to integer mapping (inverse of above)\n",
    "token2int = {v: k for k, v in int2token.items()}\n",
    "\n",
    "token2int['can'], int2token[1127]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_thres = 150000\n",
    "\n",
    "x_train = x[:split_thres]\n",
    "x_val = x[split_thres:]\n",
    "y_train = y[:split_thres]\n",
    "y_val = y[split_thres:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pad sequences\n",
    "Explore sequence lenghts to get the optimal padding lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(i.split()) for i in x_train])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max lenght should be 5\n",
    "max_text_len = 5\n",
    "\n",
    "def pad_sequences(seq, n):\n",
    "    # get tokens from seq\n",
    "    seq = seq.split()\n",
    "    # check if seq len < n\n",
    "    if len(seq)<n:\n",
    "        for i in range(n-len(seq)):\n",
    "            seq.append(\"<pad>\")\n",
    "    return \" \".join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences\n",
    "x_train_pad = [pad_sequences(s, max_text_len) for s in x_train]\n",
    "y_train_pad = [pad_sequences(s, max_text_len) for s in y_train]\n",
    "\n",
    "x_val_pad = [pad_sequences(s, max_text_len) for s in x_val]\n",
    "y_val_pad = [pad_sequences(s, max_text_len) for s in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"hi i'm looking to book\",\n",
       " \"i'm looking to book a\",\n",
       " 'looking to book a table',\n",
       " 'to book a table for',\n",
       " 'book a table for korean',\n",
       " 'somewhere in southern nyc maybe',\n",
       " 'in southern nyc maybe the',\n",
       " 'southern nyc maybe the east',\n",
       " \"we don't want to sit\",\n",
       " \"don't want to sit at\",\n",
       " 'want to sit at the',\n",
       " 'to sit at the bar',\n",
       " 'sit at the bar but',\n",
       " 'at the bar but anywhere',\n",
       " 'the bar but anywhere else',\n",
       " 'bar but anywhere else is',\n",
       " 'what times are <pad> <pad>',\n",
       " \"yikes we can't do those\",\n",
       " 'let me <pad> <pad> <pad>',\n",
       " \"great let's book <pad> <pad>\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i'm looking to book a\",\n",
       " 'looking to book a table',\n",
       " 'to book a table for',\n",
       " 'book a table for korean',\n",
       " 'a table for korean fod',\n",
       " 'in southern nyc maybe the',\n",
       " 'southern nyc maybe the east',\n",
       " 'nyc maybe the east village',\n",
       " \"don't want to sit at\",\n",
       " 'want to sit at the',\n",
       " 'to sit at the bar',\n",
       " 'sit at the bar but',\n",
       " 'at the bar but anywhere',\n",
       " 'the bar but anywhere else',\n",
       " 'bar but anywhere else is',\n",
       " 'but anywhere else is fine',\n",
       " 'times are available <pad> <pad>',\n",
       " \"we can't do those times\",\n",
       " 'me check <pad> <pad> <pad>',\n",
       " \"let's book that <pad> <pad>\"]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pad[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update vocab\n",
    "int2token[0] = \"<pad>\"\n",
    "token2int[\"<pad>\"] = 0\n",
    "# get vocab size\n",
    "vocab_size = len(int2token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert padded sequences to integers\n",
    "def get_integer_seq(seq):\n",
    "    return [token2int[w] for w in seq.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply above function to x and y\n",
    "x_train_int = [get_integer_seq(s) for s in x_train_pad]\n",
    "y_train_int = [get_integer_seq(s) for s in y_train_pad]\n",
    "x_val_int = [get_integer_seq(s) for s in x_val_pad]\n",
    "y_val_int = [get_integer_seq(s) for s in y_val_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4957, 2136, 1527, 5355, 3993],\n",
       " [2136, 1527, 5355, 3993, 1270],\n",
       " [1527, 5355, 3993, 1270, 5933],\n",
       " [5355, 3993, 1270, 5933, 3466],\n",
       " [3993, 1270, 5933, 3466, 5703],\n",
       " [3557, 4420, 4628, 523, 5918],\n",
       " [4420, 4628, 523, 5918, 6052],\n",
       " [4628, 523, 5918, 6052, 1466],\n",
       " [2, 383, 3139, 5355, 167],\n",
       " [383, 3139, 5355, 167, 2972]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_int[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2136, 1527, 5355, 3993, 1270],\n",
       " [1527, 5355, 3993, 1270, 5933],\n",
       " [5355, 3993, 1270, 5933, 3466],\n",
       " [3993, 1270, 5933, 3466, 5703],\n",
       " [1270, 5933, 3466, 5703, 179],\n",
       " [4420, 4628, 523, 5918, 6052],\n",
       " [4628, 523, 5918, 6052, 1466],\n",
       " [523, 5918, 6052, 1466, 5428],\n",
       " [383, 3139, 5355, 167, 2972],\n",
       " [3139, 5355, 167, 2972, 6052]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_int[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150000, 5), (150000, 5), (55346, 5), (55346, 5))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert lists into arrays\n",
    "x_train_int = np.array(x_train_int)\n",
    "y_train_int = np.array(y_train_int)\n",
    "x_val_int = np.array(x_val_int)\n",
    "y_val_int = np.array(y_val_int)\n",
    "\n",
    "x_train_int.shape, y_train_int.shape, x_val_int.shape, y_val_int.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "-> embedding layer:</br>\n",
    "    - input dim: vocab size</br>\n",
    "    - output dim: 200 (hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLSTM(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_hidden=256,\n",
    "            n_layers=2,\n",
    "            drop_prob=0.3,\n",
    "            lr=1e-3\n",
    "        ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.drop_prob = drop_prob\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.lr = lr\n",
    "\n",
    "        self.emb_layer = nn.Embedding(vocab_size, 200)\n",
    "\n",
    "        # define LSTM\n",
    "        # as input shape is (batch size, seq len, num features)\n",
    "        # set batch_first=True\n",
    "        self.lstm = nn.LSTM(200, n_hidden, n_layers, batch_first=True)\n",
    "\n",
    "        # Droput layer\n",
    "        self.droput = nn.Dropout(drop_prob)\n",
    "\n",
    "        # Dense layer\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        # get embed layer\n",
    "        embedded = self.emb_layer(x)\n",
    "        # pass it to LSTM\n",
    "        lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "        # pass lstm_out to dropout\n",
    "        out = self.droput(lstm_out)\n",
    "        # reshape (batch size*seq_len, hidden_units)\n",
    "        out = out.reshape(-1, self.n_hidden)\n",
    "        # pass out to dense\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "            initialize first hidden and cell state for LSTM\n",
    "        \"\"\"\n",
    "        weight = next(self, batch_size)\n",
    "\n",
    "        if (torch.cuda.is_available()):\n",
    "            hidden = (\n",
    "                # this first one for the hidden state\n",
    "                weight.new(self.n_layers, batch_size, self.n_hidden).zero().cuda(),\n",
    "                # this second one for the cell state\n",
    "                weight.new(self.n_layers, batch_size, self.n_hidden).zero().cuda()\n",
    "            )\n",
    "        else:\n",
    "            hidden = (\n",
    "                # this first one for the hidden state\n",
    "                weight.new(self.n_layers, batch_size, self.n_hidden).zero(),\n",
    "                # this second one for the cell state\n",
    "                weight.new(self.n_layers, batch_size, self.n_hidden).zero()\n",
    "            )\n",
    "        \n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WordLSTM(\n",
      "  (emb_layer): Embedding(6502, 200)\n",
      "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True)\n",
      "  (droput): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=6502, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# summary\n",
    "net = WordLSTM()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to pass batches\n",
    "def get_batches(x_array, y_array, batch_size):\n",
    "    prv = 0\n",
    "    for n in range(batch_size, x_array.shape[0], batch_size):\n",
    "        # batch for input\n",
    "        x = x_array[prv:n, :]\n",
    "        # batch for target\n",
    "        y = y_array[prv:n, :]\n",
    "        prv = n\n",
    "\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
